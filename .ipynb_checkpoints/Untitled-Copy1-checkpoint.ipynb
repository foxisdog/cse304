{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9212fd9c-cc57-4892-8cc5-f4013ffa9041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy.io import mmread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "557568a9-6f75-46a4-9bf4-ea1bc8c06eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비동기 lpa\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "def async_lpa(G, max_iter=100):\n",
    "    labels = {node: i for i, node in enumerate(G.nodes())}\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        changed = False\n",
    "        nodes = list(G.nodes())\n",
    "        random.shuffle(nodes)\n",
    "        \n",
    "        new_labels = {}\n",
    "        for node in nodes:\n",
    "            if not G[node]:\n",
    "                continue\n",
    "            # 이웃 노드의 라벨 집계\n",
    "            neighbor_labels = Counter(labels[neighbor] for neighbor in G[node])\n",
    "            max_freq = max(neighbor_labels.values())\n",
    "            best_labels = [label for label, freq in neighbor_labels.items() if freq == max_freq]\n",
    "            new_label = random.choice(best_labels)\n",
    "            \n",
    "            if new_label != labels[node]:\n",
    "                changed = True\n",
    "            new_labels[node] = new_label\n",
    "        \n",
    "        if not changed:\n",
    "            break\n",
    "        labels = new_labels\n",
    "        \n",
    "    comm_dict = defaultdict(list)\n",
    "    for node, label in labels.items():\n",
    "        comm_dict[label].append(node)\n",
    "    return [sorted(nodes) for nodes in comm_dict.values()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9599ac07-5b1f-4b47-bd3b-c121dbe1757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동기 병렬처리 lpa\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def update_label(args):\n",
    "    node, labels, G = args\n",
    "    neighbors = list(G.neighbors(node))\n",
    "    if not neighbors:\n",
    "        return node, labels[node]\n",
    "    neighbor_labels = Counter(labels[n] for n in neighbors)\n",
    "    max_freq = max(neighbor_labels.values())\n",
    "    candidates = [label for label, freq in neighbor_labels.items() if freq == max_freq]\n",
    "    return node, candidates[0]  # 동점일 경우 첫 번째 선택\n",
    "\n",
    "def parallel_sync_lpa(G, max_iter=100, n_jobs=4):\n",
    "    labels = {node: i for i, node in enumerate(G.nodes())}\n",
    "    for _ in range(max_iter):\n",
    "        with ThreadPoolExecutor(max_workers=n_jobs) as executor:\n",
    "            results = executor.map(\n",
    "                update_label, \n",
    "                [(node, labels, G) for node in G.nodes()]\n",
    "            )\n",
    "        new_labels = dict(results)\n",
    "        if new_labels == labels:\n",
    "            break\n",
    "        labels = new_labels\n",
    "        \n",
    "    comm_dict = defaultdict(list)\n",
    "    for node, label in labels.items():\n",
    "        comm_dict[label].append(node)\n",
    "    return [sorted(nodes) for nodes in comm_dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "238983d9-7cea-4de5-b940-72e06f823f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 독립집합 동기 병령 lpa\n",
    "\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List, Dict, Set\n",
    "import networkx as nx\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def sync_lpa_independent_set_parallel(\n",
    "    graph: nx.Graph, \n",
    "    seed: int = None, \n",
    "    max_iter: int = 100,\n",
    "    n_jobs: int = 4\n",
    ") -> List[List[int]]:\n",
    "    \"\"\"\n",
    "    최대 독립집합 기반 동기식 LPA의 병렬 버전\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    nodes = list(graph.nodes())\n",
    "    labels = {node: idx for idx, node in enumerate(nodes)}\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        updated = False\n",
    "        mis = _find_maximal_independent_set(graph, nodes)\n",
    "        # 병렬로 새 레이블 계산\n",
    "        new_labels = {}\n",
    "        with ThreadPoolExecutor(max_workers=n_jobs) as executor:\n",
    "            futures = {\n",
    "                executor.submit(_calc_label, graph, labels, node): node\n",
    "                for node in mis\n",
    "            }\n",
    "            for future in as_completed(futures):\n",
    "                node, new_label = future.result()\n",
    "                if new_label is not None:\n",
    "                    new_labels[node] = new_label\n",
    "\n",
    "        # 레이블 업데이트 및 변경 여부 확인\n",
    "        for node, new_label in new_labels.items():\n",
    "            if labels[node] != new_label:\n",
    "                labels[node] = new_label\n",
    "                updated = True\n",
    "                \n",
    "        if not updated:\n",
    "            break\n",
    "    \n",
    "    return _group_communities(labels)\n",
    "\n",
    "def _find_maximal_independent_set(graph: nx.Graph, nodes: List[int]) -> Set[int]:\n",
    "    \"\"\"최대 독립집합(MIS) 선택 (순차, 병렬화 가능)\"\"\"\n",
    "    mis = set()\n",
    "    blocked = set()\n",
    "    shuffled_nodes = random.sample(nodes, k=len(nodes))\n",
    "    for node in shuffled_nodes:\n",
    "        if node not in blocked:\n",
    "            mis.add(node)\n",
    "            blocked.add(node)\n",
    "            blocked.update(graph.neighbors(node))\n",
    "    return mis\n",
    "\n",
    "def _calc_label(graph: nx.Graph, labels: Dict[int, int], node: int):\n",
    "    \"\"\"(병렬 실행용) 단일 노드의 새 레이블 계산\"\"\"\n",
    "    neighbors = list(graph.neighbors(node))\n",
    "    if not neighbors:\n",
    "        return node, None\n",
    "    neighbor_labels = Counter(labels[nbr] for nbr in neighbors)\n",
    "    max_count = max(neighbor_labels.values())\n",
    "    candidates = [label for label, count in neighbor_labels.items() if count == max_count]\n",
    "    return node, random.choice(candidates)\n",
    "\n",
    "def _group_communities(labels: Dict[int, int]) -> List[List[int]]:\n",
    "    \"\"\"레이블을 기반으로 커뮤니티 그룹화\"\"\"\n",
    "    communities = defaultdict(list)\n",
    "    for node, label in labels.items():\n",
    "        communities[label].append(node)\n",
    "    return list(communities.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "358f2cf9-b44b-4bfb-8725-e553b99229f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈러리티 비동기 lpa\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "import networkx as nx\n",
    "\n",
    "def async_lpa_with_modularity(G, max_iter=100, seed=None):\n",
    "    random.seed(seed)\n",
    "    labels = {node: node for node in G.nodes()}\n",
    "    m = G.number_of_edges()\n",
    "    if m == 0:\n",
    "        return [list(G.nodes())]\n",
    "    \n",
    "    communities = {\n",
    "        node: {'sum_in': 0, 'sum_tot': G.degree(node)}\n",
    "        for node in G.nodes()\n",
    "    }\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        updated = False\n",
    "        nodes = list(G.nodes())\n",
    "        random.shuffle(nodes)\n",
    "        \n",
    "        for node in nodes:\n",
    "            current_label = labels[node]\n",
    "            neighbors = list(G.neighbors(node))\n",
    "            if not neighbors:\n",
    "                continue\n",
    "            \n",
    "            neighbor_labels = [labels[n] for n in neighbors]\n",
    "            label_counts = Counter(neighbor_labels)\n",
    "            max_count = max(label_counts.values())\n",
    "            candidates = [label for label, cnt in label_counts.items() if cnt == max_count]\n",
    "            \n",
    "            new_label = current_label  # 기본값 설정\n",
    "            current_degree = G.degree(node)\n",
    "            \n",
    "            if len(candidates) == 1:\n",
    "                new_label = candidates[0]\n",
    "            else:\n",
    "                best_delta = -float('inf')\n",
    "                best_label = current_label\n",
    "                \n",
    "                for candidate in candidates:\n",
    "                    if candidate == current_label:\n",
    "                        continue\n",
    "                    \n",
    "                    # 커뮤니티 메트릭 추출\n",
    "                    sum_in_C = communities[current_label]['sum_in']\n",
    "                    sum_tot_C = communities[current_label]['sum_tot']\n",
    "                    sum_in_D = communities[candidate]['sum_in']\n",
    "                    sum_tot_D = communities[candidate]['sum_tot']\n",
    "                    \n",
    "                    # 이웃 수 계산\n",
    "                    k_i_in_C = sum(1 for n in neighbors if labels[n] == current_label)\n",
    "                    k_i_in_D = sum(1 for n in neighbors if labels[n] == candidate)\n",
    "                    \n",
    "                    # ΔQ 계산\n",
    "                    delta_Q = (\n",
    "                        (sum_in_D + k_i_in_D - (sum_in_C - k_i_in_C)) / (2 * m)\n",
    "                    ) - (\n",
    "                        ((sum_tot_D + current_degree)**2 - (sum_tot_C - current_degree)**2)\n",
    "                        / (4 * (m**2))\n",
    "                    )\n",
    "                    \n",
    "                    if delta_Q > best_delta:\n",
    "                        best_delta = delta_Q\n",
    "                        best_label = candidate\n",
    "                \n",
    "                new_label = best_label if best_delta > 0 else current_label\n",
    "            \n",
    "            # 커뮤니티 정보 갱신\n",
    "            if new_label != current_label:\n",
    "                k_i_in_C = sum(1 for n in neighbors if labels[n] == current_label)\n",
    "                k_i_in_D = sum(1 for n in neighbors if labels[n] == new_label)\n",
    "                \n",
    "                communities[current_label]['sum_in'] -= k_i_in_C\n",
    "                communities[current_label]['sum_tot'] -= current_degree\n",
    "                communities[new_label]['sum_in'] += k_i_in_D\n",
    "                communities[new_label]['sum_tot'] += current_degree\n",
    "                labels[node] = new_label\n",
    "                updated = True\n",
    "        \n",
    "        if not updated:\n",
    "            break\n",
    "    \n",
    "    community_dict = defaultdict(list)\n",
    "    for node, label in labels.items():\n",
    "        community_dict[label].append(node)\n",
    "    return list(community_dict.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76b3c797-357a-422a-8007-577c560dc512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈러리티 동기 병렬 lpa\n",
    "import random\n",
    "import networkx as nx\n",
    "from collections import defaultdict, Counter\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def compute_communities_metrics(G, labels):\n",
    "    \"\"\"커뮤니티 메트릭 계산 헬퍼 함수\"\"\"\n",
    "    sum_in = defaultdict(int)\n",
    "    sum_tot = defaultdict(int)\n",
    "    communities = defaultdict(list)\n",
    "    \n",
    "    for node, label in labels.items():\n",
    "        communities[label].append(node)\n",
    "    \n",
    "    for label, nodes in communities.items():\n",
    "        sum_tot[label] = sum(G.degree(n) for n in nodes)\n",
    "    \n",
    "    for u, v in G.edges():\n",
    "        if labels[u] == labels[v]:\n",
    "            sum_in[labels[u]] += 1\n",
    "    \n",
    "    return sum_in, sum_tot\n",
    "\n",
    "def node_label_update(args):\n",
    "    node, G, prev_labels, prev_sum_in, prev_sum_tot, m = args\n",
    "    neighbors = list(G.neighbors(node))\n",
    "    if not neighbors:\n",
    "        return node, prev_labels[node]\n",
    "    neighbor_labels = [prev_labels[n] for n in neighbors]\n",
    "    label_counts = Counter(neighbor_labels)\n",
    "    max_count = max(label_counts.values())\n",
    "    candidates = [label for label, cnt in label_counts.items() if cnt == max_count]\n",
    "    if len(candidates) == 1:\n",
    "        return node, candidates[0]\n",
    "    else:\n",
    "        current_label = prev_labels[node]\n",
    "        best_delta = -float('inf')\n",
    "        best_label = current_label\n",
    "        k_i = G.degree(node)\n",
    "        k_i_in_C = label_counts.get(current_label, 0)\n",
    "        for candidate in candidates:\n",
    "            if candidate == current_label:\n",
    "                continue\n",
    "            k_i_in_D = label_counts.get(candidate, 0)\n",
    "            sum_in_D = prev_sum_in.get(candidate, 0)\n",
    "            sum_in_C = prev_sum_in.get(current_label, 0)\n",
    "            sum_tot_D = prev_sum_tot.get(candidate, 0)\n",
    "            sum_tot_C = prev_sum_tot.get(current_label, 0)\n",
    "            delta_Q = (\n",
    "                (sum_in_D + k_i_in_D - (sum_in_C - k_i_in_C)) / (2*m)\n",
    "            ) - (\n",
    "                ((sum_tot_D + k_i)**2 - (sum_tot_C - k_i)**2)\n",
    "                / (4*(m**2))\n",
    "            )\n",
    "            if delta_Q > best_delta:\n",
    "                best_delta = delta_Q\n",
    "                best_label = candidate\n",
    "        return node, best_label if best_delta > 0 else current_label\n",
    "\n",
    "def sync_lpa_modularity_parallel(G, max_iter=100, seed=None, n_jobs=4):\n",
    "    random.seed(seed)\n",
    "    labels = {n: i for i, n in enumerate(G.nodes())}\n",
    "    m = G.number_of_edges()\n",
    "    if m == 0:\n",
    "        return [list(G.nodes())]\n",
    "    prev_labels = labels.copy()\n",
    "    prev_sum_in, prev_sum_tot = compute_communities_metrics(G, prev_labels)\n",
    "    for _ in range(max_iter):\n",
    "        args_list = [\n",
    "            (node, G, prev_labels, prev_sum_in, prev_sum_tot, m)\n",
    "            for node in G.nodes()\n",
    "        ]\n",
    "        new_labels = {}\n",
    "        with ThreadPoolExecutor(max_workers=n_jobs) as executor:\n",
    "            for node, label in executor.map(node_label_update, args_list):\n",
    "                new_labels[node] = label\n",
    "        if new_labels == prev_labels:\n",
    "            break\n",
    "        prev_labels = new_labels.copy()\n",
    "        prev_sum_in, prev_sum_tot = compute_communities_metrics(G, prev_labels)\n",
    "    communities = defaultdict(list)\n",
    "    for node, label in prev_labels.items():\n",
    "        communities[label].append(node)\n",
    "    return list(communities.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f425ef0-7c26-4c8a-941c-9095fbb7defb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈러리티 최대 독립집합 동기 병렬 lpa\n",
    "import random\n",
    "import networkx as nx\n",
    "from collections import defaultdict, Counter\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def parallel_mis(graph, nodes, n_jobs=4):\n",
    "    \"\"\"병렬 최대 독립집합(MIS) 선택 (Luby 알고리즘 스타일의 간단 병렬화)\"\"\"\n",
    "    remaining = set(nodes)\n",
    "    mis = set()\n",
    "    while remaining:\n",
    "        # 각 노드에 무작위 우선순위 할당 (병렬화 가능)\n",
    "        priorities = {node: random.random() for node in remaining}\n",
    "        selected = set()\n",
    "        # 병렬로 각 노드의 선택 여부 판단\n",
    "        def select(node):\n",
    "            return all(priorities[node] > priorities.get(neigh, -1) for neigh in graph.neighbors(node) if neigh in remaining)\n",
    "        with ThreadPoolExecutor(max_workers=n_jobs) as executor:\n",
    "            results = list(executor.map(select, remaining))\n",
    "        for node, ok in zip(remaining, results):\n",
    "            if ok:\n",
    "                selected.add(node)\n",
    "        mis.update(selected)\n",
    "        # MIS 및 그 이웃 제거\n",
    "        to_remove = set(selected)\n",
    "        for node in selected:\n",
    "            to_remove.update(graph.neighbors(node))\n",
    "        remaining -= to_remove\n",
    "    return mis\n",
    "\n",
    "def modularity_delta(graph, labels, node, old_label, new_label, sum_in, sum_tot, m):\n",
    "    \"\"\"모듈러리티 변화량 계산\"\"\"\n",
    "    k_i = graph.degree(node)\n",
    "    sum_in_old = sum_in[old_label]\n",
    "    sum_tot_old = sum_tot[old_label]\n",
    "    sum_in_new = sum_in[new_label]\n",
    "    sum_tot_new = sum_tot[new_label]\n",
    "    delta = (sum_in_new - sum_in_old + k_i) / (2 * m)\n",
    "    delta -= ((sum_tot_new + k_i)**2 - (sum_tot_old - k_i)**2) / (4 * m**2)\n",
    "    return delta\n",
    "\n",
    "def compute_communities_metrics(G, labels):\n",
    "    sum_in = defaultdict(int)\n",
    "    sum_tot = defaultdict(int)\n",
    "    communities = defaultdict(list)\n",
    "    for node, label in labels.items():\n",
    "        communities[label].append(node)\n",
    "    for label, nodes in communities.items():\n",
    "        sum_tot[label] = sum(G.degree(n) for n in nodes)\n",
    "    for u, v in G.edges():\n",
    "        if labels[u] == labels[v]:\n",
    "            sum_in[labels[u]] += 1\n",
    "    return sum_in, sum_tot\n",
    "\n",
    "def sync_lpa_mis_modularity_parallel(\n",
    "    graph: nx.Graph,\n",
    "    max_iter: int = 100,\n",
    "    seed: int = None,\n",
    "    n_jobs: int = 4\n",
    "):\n",
    "    random.seed(seed)\n",
    "    nodes = list(graph.nodes())\n",
    "    labels = {node: idx for idx, node in enumerate(nodes)}\n",
    "    m = graph.number_of_edges()\n",
    "    sum_in, sum_tot = compute_communities_metrics(graph, labels)\n",
    "    for _ in range(max_iter):\n",
    "        # 1. 병렬 MIS 선택\n",
    "        mis = parallel_mis(graph, nodes, n_jobs)\n",
    "        # 2. MIS 내 노드 병렬 라벨 업데이트\n",
    "        def update_label(node):\n",
    "            neighbors = list(graph.neighbors(node))\n",
    "            if not neighbors:\n",
    "                return node, labels[node]\n",
    "            counts = Counter(labels[nbr] for nbr in neighbors)\n",
    "            max_count = max(counts.values())\n",
    "            candidates = [label for label, cnt in counts.items() if cnt == max_count]\n",
    "            if len(candidates) == 1:\n",
    "                return node, candidates[0]\n",
    "            # 동률: 모듈러리티 최대화\n",
    "            current_label = labels[node]\n",
    "            best_label = current_label\n",
    "            best_delta = -float('inf')\n",
    "            for candidate in candidates:\n",
    "                delta = modularity_delta(graph, labels, node, current_label, candidate, sum_in, sum_tot, m)\n",
    "                if delta > best_delta:\n",
    "                    best_delta = delta\n",
    "                    best_label = candidate\n",
    "            return node, best_label if best_delta > 0 else current_label\n",
    "        new_labels = {}\n",
    "        with ThreadPoolExecutor(max_workers=n_jobs) as executor:\n",
    "            for node, label in executor.map(update_label, mis):\n",
    "                new_labels[node] = label\n",
    "        # 3. 라벨 및 메트릭 동기 갱신\n",
    "        changed = False\n",
    "        for node, new_label in new_labels.items():\n",
    "            if labels[node] != new_label:\n",
    "                old_label = labels[node]\n",
    "                for nbr in graph.neighbors(node):\n",
    "                    if labels[nbr] == old_label:\n",
    "                        sum_in[old_label] -= 1\n",
    "                    if labels[nbr] == new_label:\n",
    "                        sum_in[new_label] += 1\n",
    "                sum_tot[old_label] -= graph.degree(node)\n",
    "                sum_tot[new_label] += graph.degree(node)\n",
    "                labels[node] = new_label\n",
    "                changed = True\n",
    "        if not changed:\n",
    "            break\n",
    "    # 결과 그룹화\n",
    "    communities = defaultdict(list)\n",
    "    for node, label in labels.items():\n",
    "        communities[label].append(node)\n",
    "    return list(communities.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99cdf515-6408-4a73-8a17-f9ec8b96e9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "\n",
    "def calculate_nmi(true_labels, graph, communities):\n",
    "    \"\"\"\n",
    "    true_labels : list of int, 길이 == 노드 수\n",
    "    graph       : networkx Graph 또는 __len__이 정의된 객체\n",
    "    communities : List of List or Set, 각 서브리스트/서브셋이 하나의 커뮤니티를 구성하는 노드 ID들\n",
    "    \"\"\"\n",
    "    # pred_labels 초기화: 노드 수만큼 0으로 채운 리스트 생성\n",
    "    pred_labels = [0] * len(graph)\n",
    "\n",
    "    # 커뮤니티별 인덱스를 pred_labels에 할당\n",
    "    for i, com in enumerate(communities):\n",
    "        for node in com:\n",
    "            pred_labels[node] = i\n",
    "\n",
    "    # NMI 계산 및 반환\n",
    "    return normalized_mutual_info_score(true_labels, pred_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1ced72c-c00f-46ca-ac24-676eea4a435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.karate_club_graph()\n",
    "true_labels_karate = []\n",
    "for node in graph.nodes:\n",
    "    label = graph.nodes[node]['club']\n",
    "    true_labels_karate.append(1 if label == 'Officer' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4563b0b-d592-4518-8ab1-6744640dd53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#돌고래\n",
    "matrix = mmread(\"./soc-dolphins/soc-dolphins.mtx\")\n",
    "# scipy 희소 행렬을 NetworkX 그래프로 변환\n",
    "\n",
    "dolphin_graph = nx.from_scipy_sparse_array(matrix)\n",
    "\n",
    "true_labels_dolphins = [\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,1,1,0,0,0,0,0,1,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    1,0,0,0,0,0,0,0,0,0,\n",
    "    1,1,1,1,1,1,1,1,1,1,\n",
    "    1,1,1,1,1,1,1,1,1,1,\n",
    "    1,1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efdbac7a-b483-4c88-a151-1055ff585407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "cora_graph = to_networkx(data)\n",
    "true_labels_cora = data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b83448-720f-494a-a6cb-f02ba40aeff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: karate\n",
      "  async_lpa completed\n",
      "  parallel_sync_lpa completed\n",
      "  sync_lpa_independent_set_parallel completed\n",
      "  async_lpa_with_modularity completed\n",
      "  sync_lpa_modularity_parallel completed\n",
      "  sync_lpa_mis_modularity_parallel completed\n",
      "Processing dataset: dolphins\n",
      "  async_lpa completed\n",
      "  parallel_sync_lpa completed\n",
      "  sync_lpa_independent_set_parallel completed\n",
      "  async_lpa_with_modularity completed\n",
      "  sync_lpa_modularity_parallel completed\n",
      "  sync_lpa_mis_modularity_parallel completed\n",
      "Processing dataset: cora\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from statistics import mean, stdev\n",
    "from collections import defaultdict\n",
    "\n",
    "# 데이터셋 준비 (Cora는 실제 데이터 로딩 코드 필요)\n",
    "datasets = {\n",
    "    \"karate\": (nx.karate_club_graph(), true_labels_karate),\n",
    "    \"dolphins\": (dolphin_graph, true_labels_dolphins),\n",
    "    \"cora\": (cora_graph, true_labels_cora)  # Cora 데이터 로딩 코드 구현 필요\n",
    "}\n",
    "\n",
    "algorithms = {\n",
    "    \"async_lpa\": async_lpa,\n",
    "    \"parallel_sync_lpa\": parallel_sync_lpa,\n",
    "    \"sync_lpa_independent_set_parallel\": sync_lpa_independent_set_parallel,\n",
    "    \"async_lpa_with_modularity\": async_lpa_with_modularity,\n",
    "    \"sync_lpa_modularity_parallel\": sync_lpa_modularity_parallel,\n",
    "    \"sync_lpa_mis_modularity_parallel\": sync_lpa_mis_modularity_parallel\n",
    "}\n",
    "\n",
    "def benchmark_algorithm(algo_func, graph, true_labels, n_runs=100):\n",
    "    results = {'nmi': [], 'time': []}\n",
    "    \n",
    "    for _ in range(n_runs):\n",
    "        start_time = time.perf_counter()\n",
    "        communities = algo_func(graph)\n",
    "        elapsed = time.perf_counter() - start_time\n",
    "        \n",
    "        nmi = calculate_nmi(true_labels, graph, communities)\n",
    "        results['nmi'].append(nmi)\n",
    "        results['time'].append(elapsed)\n",
    "    \n",
    "    return {\n",
    "        'avg_nmi': mean(results['nmi']),\n",
    "        'std_nmi': stdev(results['nmi']) if len(results['nmi']) > 1 else 0,\n",
    "        'avg_time': mean(results['time']),\n",
    "        'total_time': sum(results['time'])\n",
    "    }\n",
    "\n",
    "def run_benchmark(n_runs=100, n_jobs=4):\n",
    "    benchmark_results = []\n",
    "    \n",
    "    for ds_name, (G, true_labels) in datasets.items():\n",
    "        print(f\"Processing dataset: {ds_name}\")\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=n_jobs) as executor:\n",
    "            futures = []\n",
    "            for algo_name, algo in algorithms.items():\n",
    "                futures.append(\n",
    "                    executor.submit(\n",
    "                        benchmark_algorithm,\n",
    "                        algo,\n",
    "                        G.copy(),\n",
    "                        true_labels,\n",
    "                        n_runs\n",
    "                    )\n",
    "                )\n",
    "            \n",
    "            for (algo_name, algo), future in zip(algorithms.items(), futures):\n",
    "                result = future.result()\n",
    "                benchmark_results.append({\n",
    "                    'Dataset': ds_name,\n",
    "                    'Algorithm': algo_name,\n",
    "                    'Avg_NMI': result['avg_nmi'],\n",
    "                    'Std_NMI': result['std_nmi'],\n",
    "                    'Avg_Time(s)': result['avg_time'],\n",
    "                    'Total_Time(s)': result['total_time']\n",
    "                })\n",
    "                print(f\"  {algo_name} completed\")\n",
    "\n",
    "    # CSV로 저장\n",
    "    df = pd.DataFrame(benchmark_results)\n",
    "    df.to_csv('lpa_benchmark_results.csv', index=False)\n",
    "    return df\n",
    "\n",
    "# 실행 (n_jobs는 CPU 코어 수에 맞게 조정)\n",
    "results_df = run_benchmark(n_runs=100, n_jobs=16)\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
