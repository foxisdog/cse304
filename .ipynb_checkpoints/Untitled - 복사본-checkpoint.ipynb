{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9212fd9c-cc57-4892-8cc5-f4013ffa9041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy.io import mmread\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "557568a9-6f75-46a4-9bf4-ea1bc8c06eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "def async_lpa(G, max_iter=100):\n",
    "    labels = {node: i for i, node in enumerate(G.nodes())}\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        changed = False\n",
    "        nodes = list(G.nodes())\n",
    "        random.shuffle(nodes)  # 비동기식의 핵심: 무작위 순서\n",
    "        \n",
    "        for node in nodes:\n",
    "            if not G[node]:  # 이웃 없는 노드 스킵\n",
    "                continue\n",
    "                \n",
    "            # 현재 그래프의 실시간 레이블 사용 (비동기식 핵심)\n",
    "            neighbor_labels = [labels[nbr] for nbr in G[node]]\n",
    "            if not neighbor_labels:  # 이웃 레이블 없을 경우\n",
    "                continue\n",
    "                \n",
    "            # 레이블 통계 계산\n",
    "            label_counts = defaultdict(int)\n",
    "            for lbl in neighbor_labels:\n",
    "                label_counts[lbl] += 1\n",
    "                \n",
    "            max_count = max(label_counts.values())\n",
    "            candidates = [lbl for lbl, cnt in label_counts.items() \n",
    "                         if cnt == max_count]\n",
    "            \n",
    "            # 변경 여부 판단\n",
    "            new_label = random.choice(candidates) if candidates else labels[node]\n",
    "            if new_label != labels[node]:\n",
    "                labels[node] = new_label  # 즉시 업데이트 (비동기식)\n",
    "                changed = True\n",
    "                \n",
    "        if not changed:\n",
    "            break\n",
    "    \n",
    "    # 커뮤니티 구성\n",
    "    comm_dict = defaultdict(list)\n",
    "    for node, label in labels.items():\n",
    "        comm_dict[label].append(node)\n",
    "    return [sorted(nodes) for nodes in comm_dict.values()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9599ac07-5b1f-4b47-bd3b-c121dbe1757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "def sync_lpa(G, max_iter=100):\n",
    "    labels = {node: i for i, node in enumerate(G.nodes())}\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        changed = False\n",
    "        new_labels = {}  # 동기식의 핵심: 새로운 레이블을 임시 저장\n",
    "        \n",
    "        # 모든 노드에 대해 새로운 레이블 계산 (기존 레이블 기준)\n",
    "        for node in G.nodes():\n",
    "            if not G[node]:  # 이웃 없는 노드는 기존 레이블 유지\n",
    "                new_labels[node] = labels[node]\n",
    "                continue\n",
    "                \n",
    "            # 현재 iteration 시작 시점의 레이블 사용 (동기식 핵심)\n",
    "            neighbor_labels = [labels[nbr] for nbr in G[node]]\n",
    "            if not neighbor_labels:\n",
    "                new_labels[node] = labels[node]\n",
    "                continue\n",
    "                \n",
    "            # 레이블 통계 계산\n",
    "            label_counts = defaultdict(int)\n",
    "            for lbl in neighbor_labels:\n",
    "                label_counts[lbl] += 1\n",
    "                \n",
    "            max_count = max(label_counts.values())\n",
    "            candidates = [lbl for lbl, cnt in label_counts.items() \n",
    "                         if cnt == max_count]\n",
    "            \n",
    "            # 새로운 레이블 결정\n",
    "            new_label = random.choice(candidates) if candidates else labels[node]\n",
    "            new_labels[node] = new_label\n",
    "            \n",
    "            if new_label != labels[node]:\n",
    "                changed = True\n",
    "        \n",
    "        # 모든 노드의 레이블을 동시에 업데이트 (동기식 핵심)\n",
    "        labels = new_labels\n",
    "        \n",
    "        if not changed:\n",
    "            break\n",
    "    \n",
    "    # 커뮤니티 구성\n",
    "    comm_dict = defaultdict(list)\n",
    "    for node, label in labels.items():\n",
    "        comm_dict[label].append(node)\n",
    "    return [sorted(nodes) for nodes in comm_dict.values()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "238983d9-7cea-4de5-b940-72e06f823f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 독립집합 동기 병령 lpa\n",
    "\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import networkx as nx\n",
    "\n",
    "def find_maximal_independent_set(G, nodes):\n",
    "    \"\"\"탐욕적 방법으로 최대 독립집합 찾기\"\"\"\n",
    "    independent_set = set()\n",
    "    remaining_nodes = set(nodes)\n",
    "    \n",
    "    while remaining_nodes:\n",
    "        # 남은 노드 중 차수가 가장 낮은 노드 선택 (탐욕적 전략)\n",
    "        node = min(remaining_nodes, key=lambda n: len([nbr for nbr in G[n] if nbr in remaining_nodes]))\n",
    "        \n",
    "        # 독립집합에 추가\n",
    "        independent_set.add(node)\n",
    "        remaining_nodes.remove(node)\n",
    "        \n",
    "        # 이웃 노드들을 남은 노드에서 제거\n",
    "        neighbors_to_remove = set(G[node]) & remaining_nodes\n",
    "        remaining_nodes -= neighbors_to_remove\n",
    "    \n",
    "    return independent_set\n",
    "\n",
    "def sync_lpa_with_mis(G, max_iter=100):\n",
    "    labels = {node: i for i, node in enumerate(G.nodes())}\n",
    "    iteration_count = 0\n",
    "    all_nodes = list(G.nodes())\n",
    "    \n",
    "    while iteration_count < max_iter:\n",
    "        changed = False\n",
    "        remaining_nodes = set(all_nodes)  # 매 라운드마다 모든 노드로 초기화\n",
    "        \n",
    "        # 한 라운드: 모든 노드가 최소 1번씩 업데이트될 때까지\n",
    "        while remaining_nodes:\n",
    "            new_labels = labels.copy()\n",
    "            \n",
    "            # 남은 노드들에서 독립집합 찾기\n",
    "            independent_set = find_maximal_independent_set(G, list(remaining_nodes))\n",
    "            \n",
    "            # 독립집합의 노드들 업데이트\n",
    "            for node in independent_set:\n",
    "                if not G[node]:\n",
    "                    continue\n",
    "                    \n",
    "                neighbor_labels = [labels[nbr] for nbr in G[node]]\n",
    "                if not neighbor_labels:\n",
    "                    continue\n",
    "                    \n",
    "                label_counts = defaultdict(int)\n",
    "                for lbl in neighbor_labels:\n",
    "                    label_counts[lbl] += 1\n",
    "                    \n",
    "                max_count = max(label_counts.values())\n",
    "                candidates = [lbl for lbl, cnt in label_counts.items() \n",
    "                             if cnt == max_count]\n",
    "                \n",
    "                new_label = random.choice(candidates) if candidates else labels[node]\n",
    "                new_labels[node] = new_label\n",
    "                \n",
    "                if new_label != labels[node]:\n",
    "                    changed = True\n",
    "            \n",
    "            # 업데이트된 노드들을 남은 노드에서 제거\n",
    "            remaining_nodes -= set(independent_set)\n",
    "            labels = new_labels\n",
    "        \n",
    "        iteration_count += 1\n",
    "        \n",
    "        # 변화가 없으면 수렴으로 간주하고 종료\n",
    "        if not changed:\n",
    "            break\n",
    "    \n",
    "    # 커뮤니티 구성\n",
    "    comm_dict = defaultdict(list)\n",
    "    for node, label in labels.items():\n",
    "        comm_dict[label].append(node)\n",
    "    return [sorted(nodes) for nodes in comm_dict.values()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99cdf515-6408-4a73-8a17-f9ec8b96e9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "\n",
    "def calculate_nmi(true_labels, graph, communities):\n",
    "    \"\"\"\n",
    "    true_labels : list of int, 길이 == 노드 수\n",
    "    graph       : networkx Graph 또는 __len__이 정의된 객체\n",
    "    communities : List of List or Set, 각 서브리스트/서브셋이 하나의 커뮤니티를 구성하는 노드 ID들\n",
    "    \"\"\"\n",
    "    # pred_labels 초기화: 노드 수만큼 0으로 채운 리스트 생성\n",
    "    pred_labels = [0] * len(graph)\n",
    "\n",
    "    # 커뮤니티별 인덱스를 pred_labels에 할당\n",
    "    for i, com in enumerate(communities):\n",
    "        for node in com:\n",
    "            pred_labels[node] = i\n",
    "\n",
    "    # NMI 계산 및 반환\n",
    "    return normalized_mutual_info_score(true_labels, pred_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1ced72c-c00f-46ca-ac24-676eea4a435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.karate_club_graph()\n",
    "true_labels_karate = []\n",
    "for node in graph.nodes:\n",
    "    label = graph.nodes[node]['club']\n",
    "    true_labels_karate.append(1 if label == 'Officer' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1ba6c29-2f54-4df5-8051-aad2c2be86e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "karate    async LPA    mean :  0.6064299525704413  std :  0.19505698941582847 time :  0.46\n",
      "karate    sync LPA    mean :  0.4854464036300077  std :  0.20808481189402434 time :  19.54\n",
      "karate    sync_mis LPA    mean :  0.6592472852084993  std :  0.1252786585038043 time :  8.78\n"
     ]
    }
   ],
   "source": [
    "nmi=[]\n",
    "elapsedtime=[]\n",
    "for _ in range(100):\n",
    "    start_ms = int(round(time.time() * 1000))\n",
    "    com = async_lpa(graph)\n",
    "    com\n",
    "    end_ms = int(round(time.time() * 1000))\n",
    "    nmi.append( calculate_nmi(true_labels_karate, graph, com ) )\n",
    "    elapsedtime.append( end_ms - start_ms )\n",
    "print( \"karate    async LPA    mean : \", np.mean(nmi), \" std : \" , np.var(nmi)**0.5, \"time : \", np.mean(elapsedtime))\n",
    "\n",
    "nmi=[]\n",
    "elapsedtime=[]\n",
    "for _ in range(100):\n",
    "    start_ms = int(round(time.time() * 1000))\n",
    "    com = sync_lpa(graph)\n",
    "    com\n",
    "    end_ms = int(round(time.time() * 1000))\n",
    "    nmi.append( calculate_nmi(true_labels_karate, graph, com ) )\n",
    "    elapsedtime.append( end_ms - start_ms )\n",
    "print( \"karate    sync LPA    mean : \", np.mean(nmi), \" std : \" , np.var(nmi)**0.5, \"time : \", np.mean(elapsedtime))\n",
    "\n",
    "nmi=[]\n",
    "elapsedtime=[]\n",
    "for _ in range(100):\n",
    "    start_ms = int(round(time.time() * 1000))\n",
    "    com = sync_lpa_with_mis(graph)\n",
    "    com\n",
    "    end_ms = int(round(time.time() * 1000))\n",
    "    nmi.append( calculate_nmi(true_labels_karate, graph, com ) )\n",
    "    elapsedtime.append( end_ms - start_ms )\n",
    "print( \"karate    sync_mis LPA    mean : \", np.mean(nmi), \" std : \" , np.var(nmi)**0.5, \"time : \", np.mean(elapsedtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4563b0b-d592-4518-8ab1-6744640dd53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#돌고래\n",
    "matrix = mmread(\"./soc-dolphins/soc-dolphins.mtx\")\n",
    "# scipy 희소 행렬을 NetworkX 그래프로 변환\n",
    "\n",
    "dolphin_graph = nx.from_scipy_sparse_array(matrix)\n",
    "\n",
    "true_labels_dolphins = [\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,1,1,0,0,0,0,0,1,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    1,0,0,0,0,0,0,0,0,0,\n",
    "    1,1,1,1,1,1,1,1,1,1,\n",
    "    1,1,1,1,1,1,1,1,1,1,\n",
    "    1,1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac3e5f15-cfd4-4874-bc46-f9e15c263018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dolphins    async LPA    mean :  0.024975094530546676  std :  0.015478228741230777 time :  7.65\n",
      "dolphins    sync LPA    mean :  0.02357895918678621  std :  0.011109600890087674 time :  33.63\n",
      "dolphins    sync_mis LPA    mean :  0.03542398849612667  std :  0.025133252906735896 time :  47.6\n"
     ]
    }
   ],
   "source": [
    "nmi=[]\n",
    "elapsedtime=[]\n",
    "for _ in range(100):\n",
    "    start_ms = int(round(time.time() * 1000))\n",
    "    com = async_lpa(dolphin_graph)\n",
    "    com\n",
    "    end_ms = int(round(time.time() * 1000))\n",
    "    nmi.append( calculate_nmi(true_labels_dolphins, dolphin_graph, com ) )\n",
    "    elapsedtime.append( end_ms - start_ms )\n",
    "print( \"dolphins    async LPA    mean : \", np.mean(nmi), \" std : \" , np.var(nmi)**0.5, \"time : \", np.mean(elapsedtime))\n",
    "\n",
    "nmi=[]\n",
    "elapsedtime=[]\n",
    "for _ in range(100):\n",
    "    start_ms = int(round(time.time() * 1000))\n",
    "    com = sync_lpa(dolphin_graph)\n",
    "    com\n",
    "    end_ms = int(round(time.time() * 1000))\n",
    "    nmi.append( calculate_nmi(true_labels_dolphins, dolphin_graph, com ) )\n",
    "    elapsedtime.append( end_ms - start_ms )\n",
    "print( \"dolphins    sync LPA    mean : \", np.mean(nmi), \" std : \" , np.var(nmi)**0.5, \"time : \", np.mean(elapsedtime))\n",
    "\n",
    "nmi=[]\n",
    "elapsedtime=[]\n",
    "for _ in range(100):\n",
    "    start_ms = int(round(time.time() * 1000))\n",
    "    com = sync_lpa_with_mis(dolphin_graph)\n",
    "    com\n",
    "    end_ms = int(round(time.time() * 1000))\n",
    "    nmi.append( calculate_nmi(true_labels_dolphins, dolphin_graph, com ) )\n",
    "    elapsedtime.append( end_ms - start_ms )\n",
    "print( \"dolphins    sync_mis LPA    mean : \", np.mean(nmi), \" std : \" , np.var(nmi)**0.5, \"time : \", np.mean(elapsedtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efdbac7a-b483-4c88-a151-1055ff585407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "cora_graph = to_networkx(data)\n",
    "true_labels_cora = data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdaba0b2-0815-4a43-aa5c-5f631e50be81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cora    async LPA    mean :  0.4287923552520222  std :  0.0049359924564645365 time :  2724.36\n",
      "cora    sync LPA    mean :  0.41274767686855846  std :  0.0064953059922281285 time :  2607.29\n",
      "cora    sync_mis LPA    mean :  0.427814400039295  std :  0.0038574877442530218 time :  613777.6\n"
     ]
    }
   ],
   "source": [
    "nmi=[]\n",
    "elapsedtime=[]\n",
    "for _ in range(100):\n",
    "    start_ms = int(round(time.time() * 1000))\n",
    "    com = async_lpa(cora_graph)\n",
    "    com\n",
    "    end_ms = int(round(time.time() * 1000))\n",
    "    nmi.append( calculate_nmi(true_labels_cora, cora_graph, com ) )\n",
    "    elapsedtime.append( end_ms - start_ms )\n",
    "print( \"cora    async LPA    mean : \", np.mean(nmi), \" std : \" , np.var(nmi)**0.5, \"time : \", np.mean(elapsedtime))\n",
    "\n",
    "nmi=[]\n",
    "elapsedtime=[]\n",
    "for _ in range(100):\n",
    "    start_ms = int(round(time.time() * 1000))\n",
    "    com = sync_lpa(cora_graph)\n",
    "    com\n",
    "    end_ms = int(round(time.time() * 1000))\n",
    "    nmi.append( calculate_nmi(true_labels_cora, cora_graph, com ) )\n",
    "    elapsedtime.append( end_ms - start_ms )\n",
    "print( \"cora    sync LPA    mean : \", np.mean(nmi), \" std : \" , np.var(nmi)**0.5, \"time : \", np.mean(elapsedtime))\n",
    "\n",
    "nmi=[]\n",
    "elapsedtime=[]\n",
    "for _ in range(10):\n",
    "    start_ms = int(round(time.time() * 1000))\n",
    "    com = sync_lpa_with_mis(cora_graph)\n",
    "    com\n",
    "    end_ms = int(round(time.time() * 1000))\n",
    "    nmi.append( calculate_nmi(true_labels_cora, cora_graph, com ) )\n",
    "    elapsedtime.append( end_ms - start_ms )\n",
    "print( \"cora    sync_mis LPA    mean : \", np.mean(nmi), \" std : \" , np.var(nmi)**0.5, \"time : \", np.mean(elapsedtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e424e09-6bd1-4e1e-8dfa-115083a6ad92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cora    sync_mis LPA    mean :  0.42782666459831775  std :  0.004237018498066012 time :  613359.0\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    start_ms = int(round(time.time() * 1000))\n",
    "    com = sync_lpa_with_mis(cora_graph)\n",
    "    com\n",
    "    end_ms = int(round(time.time() * 1000))\n",
    "    nmi.append( calculate_nmi(true_labels_cora, cora_graph, com ) )\n",
    "    elapsedtime.append( end_ms - start_ms )\n",
    "print( \"cora    sync_mis LPA    mean : \", np.mean(nmi), \" std : \" , np.var(nmi)**0.5, \"time : \", np.mean(elapsedtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02b6deb9-61da-4b9b-81e1-bcb5c7f22dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cora    sync_mis LPA    mean :  0.42860557459540655  std :  0.00411965599503738 time :  612962.5\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    start_ms = int(round(time.time() * 1000))\n",
    "    com = sync_lpa_with_mis(cora_graph)\n",
    "    com\n",
    "    end_ms = int(round(time.time() * 1000))\n",
    "    nmi.append( calculate_nmi(true_labels_cora, cora_graph, com ) )\n",
    "    elapsedtime.append( end_ms - start_ms )\n",
    "print( \"cora    sync_mis LPA    mean : \", np.mean(nmi), \" std : \" , np.var(nmi)**0.5, \"time : \", np.mean(elapsedtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc2ceb0c-c1d7-4027-8567-7b3fd4300bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cora    sync_mis LPA    mean :  0.4287261822064224  std :  0.004066486199529049 time :  612758.7\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    start_ms = int(round(time.time() * 1000))\n",
    "    com = sync_lpa_with_mis(cora_graph)\n",
    "    com\n",
    "    end_ms = int(round(time.time() * 1000))\n",
    "    nmi.append( calculate_nmi(true_labels_cora, cora_graph, com ) )\n",
    "    elapsedtime.append( end_ms - start_ms )\n",
    "print( \"cora    sync_mis LPA    mean : \", np.mean(nmi), \" std : \" , np.var(nmi)**0.5, \"time : \", np.mean(elapsedtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afb2f2d5-598e-4cc2-b668-5430914153bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cora    sync_mis LPA    mean :  0.42929331520798625  std :  0.004154880878382615 time :  612581.28\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    start_ms = int(round(time.time() * 1000))\n",
    "    com = sync_lpa_with_mis(cora_graph)\n",
    "    com\n",
    "    end_ms = int(round(time.time() * 1000))\n",
    "    nmi.append( calculate_nmi(true_labels_cora, cora_graph, com ) )\n",
    "    elapsedtime.append( end_ms - start_ms )\n",
    "print( \"cora    sync_mis LPA    mean : \", np.mean(nmi), \" std : \" , np.var(nmi)**0.5, \"time : \", np.mean(elapsedtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9026b59-d95d-4b0b-b916-d59d26ddcb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cora    sync_mis LPA    mean :  0.4293420243945339  std :  0.004127571721192989 time :  612759.25\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    start_ms = int(round(time.time() * 1000))\n",
    "    com = sync_lpa_with_mis(cora_graph)\n",
    "    com\n",
    "    end_ms = int(round(time.time() * 1000))\n",
    "    nmi.append( calculate_nmi(true_labels_cora, cora_graph, com ) )\n",
    "    elapsedtime.append( end_ms - start_ms )\n",
    "print( \"cora    sync_mis LPA    mean : \", np.mean(nmi), \" std : \" , np.var(nmi)**0.5, \"time : \", np.mean(elapsedtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "250c70f9-1d6e-40af-ad38-42f247f1bd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cora    sync_mis LPA    mean :  0.42940803454884335  std :  0.004068424068396476 time :  615346.9285714285\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    start_ms = int(round(time.time() * 1000))\n",
    "    com = sync_lpa_with_mis(cora_graph)\n",
    "    com\n",
    "    end_ms = int(round(time.time() * 1000))\n",
    "    nmi.append( calculate_nmi(true_labels_cora, cora_graph, com ) )\n",
    "    elapsedtime.append( end_ms - start_ms )\n",
    "print( \"cora    sync_mis LPA    mean : \", np.mean(nmi), \" std : \" , np.var(nmi)**0.5, \"time : \", np.mean(elapsedtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71119e74-1b28-457e-8fe5-58c5b970ee29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cora    sync_mis LPA    mean :  0.4291765128539712  std :  0.003946268055472523 time :  616769.575\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    start_ms = int(round(time.time() * 1000))\n",
    "    com = sync_lpa_with_mis(cora_graph)\n",
    "    com\n",
    "    end_ms = int(round(time.time() * 1000))\n",
    "    nmi.append( calculate_nmi(true_labels_cora, cora_graph, com ) )\n",
    "    elapsedtime.append( end_ms - start_ms )\n",
    "print( \"cora    sync_mis LPA    mean : \", np.mean(nmi), \" std : \" , np.var(nmi)**0.5, \"time : \", np.mean(elapsedtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4a04b8e-77fe-41ac-9db7-d567482b63fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cora    sync_mis LPA    mean :  0.4291168396616611  std :  0.0038296921508026416 time :  616486.3333333334\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    start_ms = int(round(time.time() * 1000))\n",
    "    com = sync_lpa_with_mis(cora_graph)\n",
    "    com\n",
    "    end_ms = int(round(time.time() * 1000))\n",
    "    nmi.append( calculate_nmi(true_labels_cora, cora_graph, com ) )\n",
    "    elapsedtime.append( end_ms - start_ms )\n",
    "print( \"cora    sync_mis LPA    mean : \", np.mean(nmi), \" std : \" , np.var(nmi)**0.5, \"time : \", np.mean(elapsedtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cac08ab6-0bb0-4851-8844-04f779e7c1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cora    sync_mis LPA    mean :  0.42917784514353763  std :  0.00379867953882354 time :  617697.13\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    start_ms = int(round(time.time() * 1000))\n",
    "    com = sync_lpa_with_mis(cora_graph)\n",
    "    com\n",
    "    end_ms = int(round(time.time() * 1000))\n",
    "    nmi.append( calculate_nmi(true_labels_cora, cora_graph, com ) )\n",
    "    elapsedtime.append( end_ms - start_ms )\n",
    "print( \"cora    sync_mis LPA    mean : \", np.mean(nmi), \" std : \" , np.var(nmi)**0.5, \"time : \", np.mean(elapsedtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9ca1c6b-d4e0-4d5a-976c-9c1dbf257e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimized_sync_lpa_with_mis(G, max_iter=100):\n",
    "    \"\"\"최적화된 MIS 기반 동기 LPA\"\"\"\n",
    "    labels = {node: i for i, node in enumerate(G.nodes())}\n",
    "    iteration_count = 0\n",
    "    all_nodes = list(G.nodes())\n",
    "    \n",
    "    # 노드 차수를 미리 계산하여 성능 향상\n",
    "    node_degrees = dict(G.degree())\n",
    "    \n",
    "    while iteration_count < max_iter:\n",
    "        changed = False\n",
    "        remaining_nodes = set(all_nodes)\n",
    "        \n",
    "        while remaining_nodes:\n",
    "            new_labels = labels.copy()\n",
    "            \n",
    "            # 최적화된 독립집합 찾기\n",
    "            independent_set = find_optimized_maximal_independent_set(G, list(remaining_nodes), node_degrees)\n",
    "            \n",
    "            for node in independent_set:\n",
    "                if not G[node]:\n",
    "                    continue\n",
    "                \n",
    "                neighbor_labels = [labels[nbr] for nbr in G[node]]\n",
    "                if not neighbor_labels:\n",
    "                    continue\n",
    "                \n",
    "                label_counts = defaultdict(int)\n",
    "                for lbl in neighbor_labels:\n",
    "                    label_counts[lbl] += 1\n",
    "                \n",
    "                max_count = max(label_counts.values())\n",
    "                candidates = [lbl for lbl, cnt in label_counts.items() \n",
    "                            if cnt == max_count]\n",
    "                \n",
    "                new_label = random.choice(candidates) if candidates else labels[node]\n",
    "                new_labels[node] = new_label\n",
    "                \n",
    "                if new_label != labels[node]:\n",
    "                    changed = True\n",
    "            \n",
    "            remaining_nodes -= set(independent_set)\n",
    "            labels = new_labels\n",
    "        \n",
    "        iteration_count += 1\n",
    "        \n",
    "        if not changed:\n",
    "            break\n",
    "    \n",
    "    # 커뮤니티 구성\n",
    "    comm_dict = defaultdict(list)\n",
    "    for node, label in labels.items():\n",
    "        comm_dict[label].append(node)\n",
    "    return [sorted(nodes) for nodes in comm_dict.values()]\n",
    "\n",
    "def find_optimized_maximal_independent_set(G, nodes, node_degrees):\n",
    "    \"\"\"최적화된 최대 독립집합 찾기\"\"\"\n",
    "    independent_set = set()\n",
    "    remaining_nodes = set(nodes)\n",
    "    \n",
    "    while remaining_nodes:\n",
    "        # 미리 계산된 차수 정보 사용\n",
    "        node = min(remaining_nodes, \n",
    "                  key=lambda n: sum(1 for nbr in G[n] if nbr in remaining_nodes))\n",
    "        \n",
    "        independent_set.add(node)\n",
    "        remaining_nodes.remove(node)\n",
    "        \n",
    "        # 이웃 노드들을 효율적으로 제거\n",
    "        neighbors_to_remove = set(G[node]) & remaining_nodes\n",
    "        remaining_nodes -= neighbors_to_remove\n",
    "    \n",
    "    return independent_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "144c3cb4-a95a-4d8c-a54a-0ef2a396d1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cora    sync_mis LPA    mean :  0.4320407475900254  std :  0.0 time :  822144.0\n"
     ]
    }
   ],
   "source": [
    "# 최적화 버전\n",
    "nmi=[]\n",
    "elapsedtime=[]\n",
    "for _ in range(1):\n",
    "    start_ms = int(round(time.time() * 1000))\n",
    "    com = optimized_sync_lpa_with_mis(cora_graph)\n",
    "    com\n",
    "    end_ms = int(round(time.time() * 1000))\n",
    "    nmi.append( calculate_nmi(true_labels_cora, cora_graph, com ) )\n",
    "    elapsedtime.append( end_ms - start_ms )\n",
    "print( \"cora    sync_mis LPA    mean : \", np.mean(nmi), \" std : \" , np.var(nmi)**0.5, \"time : \", np.mean(elapsedtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a680309-a37e-46e9-a08c-da64795aaa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modularity_async_lpa(G, max_iter=100):\n",
    "    \"\"\"Modularity를 고려한 비동기 LPA\"\"\"\n",
    "    labels = {node: i for i, node in enumerate(G.nodes())}\n",
    "    total_edges = G.number_of_edges() * 2  # 무방향 그래프에서 총 엣지 수\n",
    "    node_degrees = dict(G.degree())\n",
    "    \n",
    "    for iteration in range(max_iter):\n",
    "        changed = False\n",
    "        nodes = list(G.nodes())\n",
    "        random.shuffle(nodes)\n",
    "        \n",
    "        for node in nodes:\n",
    "            if not G[node]:\n",
    "                continue\n",
    "                \n",
    "            current_label = labels[node]\n",
    "            best_label = current_label\n",
    "            best_modularity_gain = 0\n",
    "            \n",
    "            # 이웃 라벨들과 각각에 대한 modularity 증가량 계산\n",
    "            neighbor_labels = set(labels[nbr] for nbr in G[node])\n",
    "            \n",
    "            for candidate_label in neighbor_labels:\n",
    "                modularity_gain = calculate_modularity_gain(\n",
    "                    G, labels, node, current_label, candidate_label, \n",
    "                    total_edges, node_degrees\n",
    "                )\n",
    "                \n",
    "                if modularity_gain > best_modularity_gain:\n",
    "                    best_modularity_gain = modularity_gain\n",
    "                    best_label = candidate_label\n",
    "            \n",
    "            # Modularity 증가가 있는 경우에만 라벨 변경\n",
    "            if best_label != current_label and best_modularity_gain > 0:\n",
    "                labels[node] = best_label\n",
    "                changed = True\n",
    "        \n",
    "        if not changed:\n",
    "            break\n",
    "    \n",
    "    # 커뮤니티 구성\n",
    "    comm_dict = defaultdict(list)\n",
    "    for node, label in labels.items():\n",
    "        comm_dict[label].append(node)\n",
    "    return [sorted(nodes) for nodes in comm_dict.values()]\n",
    "\n",
    "def calculate_modularity_gain(G, labels, node, old_label, new_label, total_edges, node_degrees):\n",
    "    \"\"\"노드의 라벨 변경으로 인한 modularity 증가량 계산\"\"\"\n",
    "    if old_label == new_label:\n",
    "        return 0\n",
    "    \n",
    "    # 현재 노드의 차수\n",
    "    ki = node_degrees[node]\n",
    "    \n",
    "    # old_label 커뮤니티와의 연결 수\n",
    "    ki_in_old = sum(1 for nbr in G[node] if labels[nbr] == old_label)\n",
    "    \n",
    "    # new_label 커뮤니티와의 연결 수  \n",
    "    ki_in_new = sum(1 for nbr in G[node] if labels[nbr] == new_label)\n",
    "    \n",
    "    # old_label 커뮤니티의 총 차수\n",
    "    sigma_old = sum(node_degrees[n] for n, label in labels.items() if label == old_label)\n",
    "    \n",
    "    # new_label 커뮤니티의 총 차수\n",
    "    sigma_new = sum(node_degrees[n] for n, label in labels.items() if label == new_label)\n",
    "    \n",
    "    # Modularity 변화량 계산\n",
    "    delta_q = (ki_in_new - ki_in_old) / total_edges - ki * (sigma_new - sigma_old) / (total_edges ** 2)\n",
    "    \n",
    "    return delta_q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbc2627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modularity_sync_lpa(G, max_iter=100):\n",
    "    \"\"\"Modularity를 고려한 동기 LPA\"\"\"\n",
    "    labels = {node: i for i, node in enumerate(G.nodes())}\n",
    "    total_edges = G.number_of_edges() * 2\n",
    "    node_degrees = dict(G.degree())\n",
    "    \n",
    "    for iteration in range(max_iter):\n",
    "        changed = False\n",
    "        new_labels = {}\n",
    "        \n",
    "        for node in G.nodes():\n",
    "            if not G[node]:\n",
    "                new_labels[node] = labels[node]\n",
    "                continue\n",
    "            \n",
    "            current_label = labels[node]\n",
    "            best_label = current_label\n",
    "            best_modularity_gain = 0\n",
    "            \n",
    "            # 이웃 라벨들 수집\n",
    "            neighbor_labels = set(labels[nbr] for nbr in G[node])\n",
    "            \n",
    "            # 각 후보 라벨에 대해 modularity 증가량 계산\n",
    "            for candidate_label in neighbor_labels:\n",
    "                modularity_gain = calculate_modularity_gain(\n",
    "                    G, labels, node, current_label, candidate_label,\n",
    "                    total_edges, node_degrees\n",
    "                )\n",
    "                \n",
    "                if modularity_gain > best_modularity_gain:\n",
    "                    best_modularity_gain = modularity_gain\n",
    "                    best_label = candidate_label\n",
    "            \n",
    "            new_labels[node] = best_label\n",
    "            if best_label != current_label:\n",
    "                changed = True\n",
    "        \n",
    "        # 모든 노드를 동시에 업데이트\n",
    "        labels = new_labels\n",
    "        \n",
    "        if not changed:\n",
    "            break\n",
    "    \n",
    "    # 커뮤니티 구성\n",
    "    comm_dict = defaultdict(list)\n",
    "    for node, label in labels.items():\n",
    "        comm_dict[label].append(node)\n",
    "    return [sorted(nodes) for nodes in comm_dict.values()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f19fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modularity_sync_lpa_with_mis(G, max_iter=100):\n",
    "    \"\"\"Modularity를 고려한 MIS 기반 동기 LPA\"\"\"\n",
    "    labels = {node: i for i, node in enumerate(G.nodes())}\n",
    "    total_edges = G.number_of_edges() * 2\n",
    "    node_degrees = dict(G.degree())\n",
    "    iteration_count = 0\n",
    "    all_nodes = list(G.nodes())\n",
    "    \n",
    "    while iteration_count < max_iter:\n",
    "        changed = False\n",
    "        remaining_nodes = set(all_nodes)\n",
    "        \n",
    "        while remaining_nodes:\n",
    "            new_labels = labels.copy()\n",
    "            \n",
    "            # 독립집합 찾기\n",
    "            independent_set = find_maximal_independent_set(G, list(remaining_nodes))\n",
    "            \n",
    "            # 독립집합의 노드들에 대해 modularity 기반 라벨 업데이트\n",
    "            for node in independent_set:\n",
    "                if not G[node]:\n",
    "                    continue\n",
    "                \n",
    "                current_label = labels[node]\n",
    "                best_label = current_label\n",
    "                best_modularity_gain = 0\n",
    "                \n",
    "                # 이웃 라벨들 수집\n",
    "                neighbor_labels = set(labels[nbr] for nbr in G[node])\n",
    "                \n",
    "                # Modularity 증가량이 가장 큰 라벨 선택\n",
    "                for candidate_label in neighbor_labels:\n",
    "                    modularity_gain = calculate_modularity_gain(\n",
    "                        G, labels, node, current_label, candidate_label,\n",
    "                        total_edges, node_degrees\n",
    "                    )\n",
    "                    \n",
    "                    if modularity_gain > best_modularity_gain:\n",
    "                        best_modularity_gain = modularity_gain\n",
    "                        best_label = candidate_label\n",
    "                \n",
    "                new_labels[node] = best_label\n",
    "                if best_label != current_label:\n",
    "                    changed = True\n",
    "            \n",
    "            # 처리된 노드들 제거\n",
    "            remaining_nodes -= set(independent_set)\n",
    "            labels = new_labels\n",
    "        \n",
    "        iteration_count += 1\n",
    "        \n",
    "        if not changed:\n",
    "            break\n",
    "    \n",
    "    # 커뮤니티 구성\n",
    "    comm_dict = defaultdict(list)\n",
    "    for node, label in labels.items():\n",
    "        comm_dict[label].append(node)\n",
    "    return [sorted(nodes) for nodes in comm_dict.values()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3752d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_modularity(G, communities):\n",
    "    \"\"\"커뮤니티 분할의 전체 modularity 계산\"\"\"\n",
    "    # 노드-커뮤니티 매핑 생성\n",
    "    node_to_comm = {}\n",
    "    for i, comm in enumerate(communities):\n",
    "        for node in comm:\n",
    "            node_to_comm[node] = i\n",
    "    \n",
    "    total_edges = G.number_of_edges()\n",
    "    if total_edges == 0:\n",
    "        return 0\n",
    "    \n",
    "    modularity = 0\n",
    "    node_degrees = dict(G.degree())\n",
    "    \n",
    "    for edge in G.edges():\n",
    "        u, v = edge\n",
    "        # 같은 커뮤니티에 속하는 엣지인지 확인\n",
    "        if node_to_comm[u] == node_to_comm[v]:\n",
    "            modularity += 1 - (node_degrees[u] * node_degrees[v]) / (2 * total_edges)\n",
    "        else:\n",
    "            modularity -= (node_degrees[u] * node_degrees[v]) / (2 * total_edges)\n",
    "    \n",
    "    return modularity / (2 * total_edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94c491c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "노드 수: 115\n",
      "엣지 수: 613\n",
      "평균 차수: 10.66\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.read_edgelist('out.dimacs10-football', \n",
    "                     create_using=nx.Graph(), \n",
    "                     nodetype=int)\n",
    "\n",
    "# 기본 정보 출력\n",
    "print(f\"노드 수: {G.number_of_nodes()}\")\n",
    "print(f\"엣지 수: {G.number_of_edges()}\")\n",
    "print(f\"평균 차수: {2 * G.number_of_edges() / G.number_of_nodes():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6cbb1761-b1c8-4e93-9a7d-798c10e34060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 컨퍼런스 정보 ===\n",
      "Atlantic Coast: 9개 팀\n",
      "Big East: 8개 팀\n",
      "Big Ten: 11개 팀\n",
      "Big Twelve: 12개 팀\n",
      "Conference USA: 11개 팀\n",
      "Independents: 5개 팀\n",
      "Mid-American: 13개 팀\n",
      "Mountain West: 8개 팀\n",
      "Pacific Ten: 10개 팀\n",
      "Southeastern: 12개 팀\n",
      "Sun Belt: 9개 팀\n",
      "Western Athletic: 7개 팀\n"
     ]
    }
   ],
   "source": [
    "# Football 네트워크의 12개 컨퍼런스 (커뮤니티)\n",
    "FOOTBALL_CONFERENCES = {\n",
    "    'Atlantic Coast': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'Big East': [10, 11, 12, 13, 14, 15, 16, 17],\n",
    "    'Big Ten': [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28],\n",
    "    'Big Twelve': [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40],\n",
    "    'Conference USA': [41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51],\n",
    "    'Independents': [52, 53, 54, 55, 56],\n",
    "    'Mid-American': [57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n",
    "    'Mountain West': [70, 71, 72, 73, 74, 75, 76, 77],\n",
    "    'Pacific Ten': [78, 79, 80, 81, 82, 83, 84, 85, 86, 87],\n",
    "    'Southeastern': [88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n",
    "    'Sun Belt': [100, 101, 102, 103, 104, 105, 106, 107, 108],\n",
    "    'Western Athletic': [109, 110, 111, 112, 113, 114, 115]\n",
    "}\n",
    "\n",
    "print(\"=== 컨퍼런스 정보 ===\")\n",
    "for conf, teams in FOOTBALL_CONFERENCES.items():\n",
    "    print(f\"{conf}: {len(teams)}개 팀\")\n",
    "\n",
    "def relabel_graph_nodes(G):\n",
    "    \"\"\"그래프 노드를 0부터 시작하도록 재매핑\"\"\"\n",
    "    mapping = {node: i for i, node in enumerate(sorted(G.nodes()))}\n",
    "    return nx.relabel_nodes(G, mapping)\n",
    "\n",
    "G = relabel_graph_nodes(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2fe68a4f-f4ed-4287-a30e-ce2788c277b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_football = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d13fe8b2-7889-4347-8ab4-e05268e6898d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.463221840251306"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_nmi(true_football, G, async_lpa(G) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "618fc6c5-4194-4035-8bec-4b4ee3d02a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOOTBALL    async LPA    mean :  0.4769406244296301  std :  0.027218876575115767 time :  6.95\n",
      "FOOTBALL    sync LPA    mean :  0.4778621403653957  std :  0.018788251174715748 time :  36.24\n",
      "FOOTBALL    sync_mis LPA    mean :  0.4873249438544196  std :  0.02103313811994341 time :  64.74\n"
     ]
    }
   ],
   "source": [
    "nmi=[]\n",
    "elapsedtime=[]\n",
    "for _ in range(100):\n",
    "    start_ms = int(round(time.time() * 1000))\n",
    "    com = async_lpa(G)\n",
    "    com\n",
    "    end_ms = int(round(time.time() * 1000))\n",
    "    nmi.append( calculate_nmi(true_football, G, com ) )\n",
    "    elapsedtime.append( end_ms - start_ms )\n",
    "print( \"FOOTBALL    async LPA    mean : \", np.mean(nmi), \" std : \" , np.var(nmi)**0.5, \"time : \", np.mean(elapsedtime))\n",
    "\n",
    "nmi=[]\n",
    "elapsedtime=[]\n",
    "for _ in range(100):\n",
    "    start_ms = int(round(time.time() * 1000))\n",
    "    com = sync_lpa(G)\n",
    "    com\n",
    "    end_ms = int(round(time.time() * 1000))\n",
    "    nmi.append( calculate_nmi(true_football, G, com ) )\n",
    "    elapsedtime.append( end_ms - start_ms )\n",
    "print( \"FOOTBALL    sync LPA    mean : \", np.mean(nmi), \" std : \" , np.var(nmi)**0.5, \"time : \", np.mean(elapsedtime))\n",
    "\n",
    "nmi=[]\n",
    "elapsedtime=[]\n",
    "for _ in range(100):\n",
    "    start_ms = int(round(time.time() * 1000))\n",
    "    com = sync_lpa_with_mis(G)\n",
    "    com\n",
    "    end_ms = int(round(time.time() * 1000))\n",
    "    nmi.append( calculate_nmi(true_football, G, com ) )\n",
    "    elapsedtime.append( end_ms - start_ms )\n",
    "print( \"FOOTBALL    sync_mis LPA    mean : \", np.mean(nmi), \" std : \" , np.var(nmi)**0.5, \"time : \", np.mean(elapsedtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e6bb35e8-23f4-4b19-8a06-e5b8fd9b3986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modularity_async_lpa(G, max_iter=100):\n",
    "    \"\"\"Modularity를 고려한 비동기 LPA\"\"\"\n",
    "    labels = {node: i for i, node in enumerate(G.nodes())}\n",
    "    total_edges = G.number_of_edges() * 2  # 무방향 그래프에서 총 엣지 수\n",
    "    node_degrees = dict(G.degree())\n",
    "    \n",
    "    for iteration in range(max_iter):\n",
    "        changed = False\n",
    "        nodes = list(G.nodes())\n",
    "        random.shuffle(nodes)\n",
    "        \n",
    "        for node in nodes:\n",
    "            if not G[node]:\n",
    "                continue\n",
    "                \n",
    "            current_label = labels[node]\n",
    "            best_label = current_label\n",
    "            best_modularity_gain = 0\n",
    "            \n",
    "            # 이웃 라벨들과 각각에 대한 modularity 증가량 계산\n",
    "            neighbor_labels = set(labels[nbr] for nbr in G[node])\n",
    "            \n",
    "            for candidate_label in neighbor_labels:\n",
    "                modularity_gain = calculate_modularity_gain(\n",
    "                    G, labels, node, current_label, candidate_label, \n",
    "                    total_edges, node_degrees\n",
    "                )\n",
    "                \n",
    "                if modularity_gain > best_modularity_gain:\n",
    "                    best_modularity_gain = modularity_gain\n",
    "                    best_label = candidate_label\n",
    "            \n",
    "            # Modularity 증가가 있는 경우에만 라벨 변경\n",
    "            if best_label != current_label and best_modularity_gain > 0:\n",
    "                labels[node] = best_label\n",
    "                changed = True\n",
    "        \n",
    "        if not changed:\n",
    "            break\n",
    "    \n",
    "    # 커뮤니티 구성\n",
    "    comm_dict = defaultdict(list)\n",
    "    for node, label in labels.items():\n",
    "        comm_dict[label].append(node)\n",
    "    return [sorted(nodes) for nodes in comm_dict.values()]\n",
    "\n",
    "def calculate_modularity_gain(G, labels, node, old_label, new_label, total_edges, node_degrees):\n",
    "    \"\"\"노드의 라벨 변경으로 인한 modularity 증가량 계산\"\"\"\n",
    "    if old_label == new_label:\n",
    "        return 0\n",
    "    \n",
    "    # 현재 노드의 차수\n",
    "    ki = node_degrees[node]\n",
    "    \n",
    "    # old_label 커뮤니티와의 연결 수\n",
    "    ki_in_old = sum(1 for nbr in G[node] if labels[nbr] == old_label)\n",
    "    \n",
    "    # new_label 커뮤니티와의 연결 수  \n",
    "    ki_in_new = sum(1 for nbr in G[node] if labels[nbr] == new_label)\n",
    "    \n",
    "    # old_label 커뮤니티의 총 차수\n",
    "    sigma_old = sum(node_degrees[n] for n, label in labels.items() if label == old_label)\n",
    "    \n",
    "    # new_label 커뮤니티의 총 차수\n",
    "    sigma_new = sum(node_degrees[n] for n, label in labels.items() if label == new_label)\n",
    "    \n",
    "    # Modularity 변화량 계산\n",
    "    delta_q = (ki_in_new - ki_in_old) / total_edges - ki * (sigma_new - sigma_old) / (total_edges ** 2)\n",
    "    \n",
    "    return delta_q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c60057ad-5041-4e1b-860b-e8adb7722db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOOTBALL    async LPA    mean :  0.49922862348706304  std :  0.009916094442067501 time :  77.01\n"
     ]
    }
   ],
   "source": [
    "nmi=[]\n",
    "elapsedtime=[]\n",
    "for _ in range(100):\n",
    "    start_ms = int(round(time.time() * 1000))\n",
    "    com = modularity_async_lpa(G)\n",
    "    com\n",
    "    end_ms = int(round(time.time() * 1000))\n",
    "    nmi.append( calculate_nmi(true_football, G, com ) )\n",
    "    elapsedtime.append( end_ms - start_ms )\n",
    "print( \"FOOTBALL    async LPA    mean : \", np.mean(nmi), \" std : \" , np.var(nmi)**0.5, \"time : \", np.mean(elapsedtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d3e00e64-e577-410a-971e-ea26ad50329c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "karate    async LPA    mean :  0.5281422945594655  std :  0.0255884029890106 time :  12.46\n"
     ]
    }
   ],
   "source": [
    "nmi=[]\n",
    "elapsedtime=[]\n",
    "for _ in range(100):\n",
    "    start_ms = int(round(time.time() * 1000))\n",
    "    com = modularity_async_lpa(graph)\n",
    "    com\n",
    "    end_ms = int(round(time.time() * 1000))\n",
    "    nmi.append( calculate_nmi(true_labels_karate, graph, com ) )\n",
    "    elapsedtime.append( end_ms - start_ms )\n",
    "print( \"karate    async LPA    mean : \", np.mean(nmi), \" std : \" , np.var(nmi)**0.5, \"time : \", np.mean(elapsedtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "91caa167-bd7b-44b5-9ced-b2040b790a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dolphin    async LPA    mean :  0.08980403116241964  std :  0.013453048492821027 time :  126.77\n"
     ]
    }
   ],
   "source": [
    "nmi=[]\n",
    "elapsedtime=[]\n",
    "for _ in range(100):\n",
    "    start_ms = int(round(time.time() * 1000))\n",
    "    com = modularity_async_lpa(dolphin_graph)\n",
    "    com\n",
    "    end_ms = int(round(time.time() * 1000))\n",
    "    nmi.append( calculate_nmi(true_labels_dolphins, dolphin_graph, com ) )\n",
    "    elapsedtime.append( end_ms - start_ms )\n",
    "print( \"dolphin    async LPA    mean : \", np.mean(nmi), \" std : \" , np.var(nmi)**0.5, \"time : \", np.mean(elapsedtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20601d0-640b-4713-b306-e0770a971d92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
